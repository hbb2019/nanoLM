{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMr47m6gom4U96NLj+Z2l9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbb2019/nanoLM/blob/main/science_label_ipynb%EF%BC%88%E5%89%AF%E6%9C%AC%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY9tNcBeF4lq",
        "outputId": "b510afb7-a3ed-4b72-cfba-6439bc3088bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3TKD2w31GAyp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/BAAI/industry_instruction_science_research_train.jsonl'"
      ],
      "metadata": {
        "id": "WNvXyPabGC7G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(file_path, lines=True)"
      ],
      "metadata": {
        "id": "fuTH7j5kGWI8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[:10000] # 时间原因，分段计算"
      ],
      "metadata": {
        "id": "0tguzyZBVtYx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'行数:{df.shape[0]}')\n",
        "print(f'列数:{df.shape[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo5ElY5SGX1N",
        "outputId": "c306e114-af7d-4c48-e428-4d8426d9aaeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "行数:10000\n",
            "列数:7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "Xj_LnHl4G3XS",
        "outputId": "17913d0d-2daa-4ed4-9591-9143812ff11a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "deita_score                                              12.915536\n",
              "rw_score                                                    -5.125\n",
              "id                                        generate_from_given_text\n",
              "instruction                                                       \n",
              "lang                                                            en\n",
              "length                                                          38\n",
              "conversations    [{'from': 'human', 'value': 'How does the clus...\n",
              "Name: 1, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>deita_score</th>\n",
              "      <td>12.915536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rw_score</th>\n",
              "      <td>-5.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>generate_from_given_text</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>instruction</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>length</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conversations</th>\n",
              "      <td>[{'from': 'human', 'value': 'How does the clus...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list\n",
        "df.iloc[1]['conversations']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jETK_bp_G-CJ",
        "outputId": "2492354d-bd47-4430-8a58-9c354bda2b43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'from': 'human',\n",
              "  'value': 'How does the clustering of microearthquakes help seismologists understand what initiates and governs an earthquake, and what insights do researchers like Ross Stein hope to gain from this?'},\n",
              " {'from': 'gpt',\n",
              "  'value': \"The clustering of microearthquakes helps seismologists understand what initiates and governs an earthquake by providing insights into the stress transfer and fault interaction processes. By analyzing the locations and patterns of microearthquakes, researchers like Ross Stein hope to gain a better understanding of how earthquakes are triggered and how stress is transferred along faults. This knowledge can help improve earthquake forecasting and hazard assessment. Stein's research focuses on the interaction between earthquakes and faults, and he hopes to learn more about the underlying mechanisms that control earthquake behavior.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取所有行的对话字符串\n",
        "def extract_conversation_strings(df):\n",
        "    conversation_strings = []\n",
        "    for _, row in df.iterrows():\n",
        "        try:\n",
        "            conversation_list = row['conversations']\n",
        "            if not isinstance(conversation_list, list) or len(conversation_list) != 2:\n",
        "                conversation_strings.append(\"unknown\")\n",
        "                continue\n",
        "            human_value = conversation_list[0].get('value', '')\n",
        "            gpt_value = conversation_list[1].get('value', '')\n",
        "            QA_part = human_value + \" \" + gpt_value\n",
        "            conversation_strings.append(QA_part)\n",
        "        except Exception as e:\n",
        "            print(f\"错误处理行: {e}\")\n",
        "            conversation_strings.append(\"error\")\n",
        "    return conversation_strings\n",
        "\n",
        "# 假设 df 是您的 DataFrame\n",
        "# 提取所有对话字符串成列表\n",
        "conversation_list = extract_conversation_strings(df)"
      ],
      "metadata": {
        "id": "iTHRkCcbW3vb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_list[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfmH_336W6Cy",
        "outputId": "b72316f3-2918-4609-d698-ac405e957580"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['在5G网络开发过程中，有哪些常见的安全挑战需要解决？ 在5G网络开发过程中，有几个常见的安全挑战需要解决。首先是网络架构的安全性，包括如何保护核心网络、边缘网络和终端设备的安全。其次是用户数据的隐私保护，如何确保用户的个人信息和通信内容在传输和存储过程中的安全性。另外，物联网设备的安全性也是一个重要的挑战，因为5G网络将连接大量的物联网设备，如何保护这些设备免受攻击和滥用是一个关键问题。此外，虚拟化和云计算技术的应用也带来了新的安全挑战，如如何保护虚拟化环境的安全和云服务提供商的安全。总的来说，在5G网络开发过程中，需要解决这些常见的安全挑战，以确保网络的安全和可靠性。',\n",
              " \"How does the clustering of microearthquakes help seismologists understand what initiates and governs an earthquake, and what insights do researchers like Ross Stein hope to gain from this? The clustering of microearthquakes helps seismologists understand what initiates and governs an earthquake by providing insights into the stress transfer and fault interaction processes. By analyzing the locations and patterns of microearthquakes, researchers like Ross Stein hope to gain a better understanding of how earthquakes are triggered and how stress is transferred along faults. This knowledge can help improve earthquake forecasting and hazard assessment. Stein's research focuses on the interaction between earthquakes and faults, and he hopes to learn more about the underlying mechanisms that control earthquake behavior.\",\n",
              " 'Can you summarize the milestones achieved by perfSONAR since its development, including the number of instances installed and the countries where it is being used? perfSONAR reached a milestone of 1,000 instances installed on networking hosts around the U.S. and in 25 other countries in January 2014. Since its development, perfSONAR has eliminated many bugs, made it easier to install, and is now a comprehensive suite of tools in one easy-to-install package. The software is used by major users like the Large Hadron Collider collaboration with users at hundreds of institutions.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QA_labels = [\n",
        "    \"math\",\n",
        "    \"chemistry\",\n",
        "    \"physics\",\n",
        "    \"biology\",\n",
        "    \"computer_science\",\n",
        "    \"earth_science\",\n",
        "    \"astronomy\",\n",
        "    \"environmental_science\",\n",
        "    \"material_science\",\n",
        "    \"engineering\",\n",
        "    \"medicine\",\n",
        "    \"statistics\",\n",
        "    \"psychology\",\n",
        "    \"neuroscience\",\n",
        "    \"data_science\"\n",
        "]"
      ],
      "metadata": {
        "id": "ycTc5M-bJCLc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# hf_token = userdata.get('HF_TOKEN')\n",
        "# from huggingface_hub import login\n",
        "# login()  # 自动使用 HF_TOKEN"
      ],
      "metadata": {
        "id": "lefWlTGSL5Q2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK01x1AIME6g",
        "outputId": "4b388dfe-13a1-45d5-894f-11cac6cf17b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "# 加载模型\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\", device=0)\n",
        "print(classifier.model.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGizqHh3HV33",
        "outputId": "ce73dc94-be66-4f2d-be71-c8fd6bb6697f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "diMYFGxGcML9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 要分类的文本\n",
        "sequence = conversation_list\n",
        "batch_size = 10\n",
        "num_batches = len(sequence) // batch_size + (1 if len(sequence) % batch_size != 0 else 0)\n"
      ],
      "metadata": {
        "id": "PkKUfngubxZQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "progress_bar = tqdm(total=len(sequence), desc=\"正在处理文本\", unit=\"条\")\n",
        "# 初始化结果列表\n",
        "all_results = []\n",
        "# 分批处理\n",
        "for i in range(0, len(sequence), batch_size):\n",
        "    # 获取当前批次\n",
        "    batch = sequence[i:i + batch_size]\n",
        "    # 对当前批次运行分类器\n",
        "    batch_results = classifier(batch, QA_labels)\n",
        "    # 将结果添加到总结果列表\n",
        "    all_results.extend(batch_results)\n",
        "    # 更新进度条，步长为当前批次的大小\n",
        "    progress_bar.update(len(batch))\n",
        "\n",
        "# 关闭进度条\n",
        "progress_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRopo5FgHtWe",
        "outputId": "e5d83891-e0cc-4fe1-c343-574c663e700e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "正在处理文本:   1%|          | 100/10000 [01:07<1:50:46,  1.49条/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "正在处理文本:  81%|████████  | 8110/10000 [1:35:43<20:22,  1.55条/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subject_labels = [v['labels'][0] for v in all_results]"
      ],
      "metadata": {
        "id": "a26GeSGmPlVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['subject_label'] = subject_labels"
      ],
      "metadata": {
        "id": "eLNERzsBXcYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['conversations', 'subject_label']].head(3))"
      ],
      "metadata": {
        "id": "S2LNdb4yXno_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# 构造新文件名（添加日期）\n",
        "# 获取当前日期（2025-04-22）\n",
        "current_date = datetime(2025, 4, 23).strftime('%Y-%m-%d')  # 格式化为 '2025-04-22'\n",
        "\n",
        "# 提取文件夹路径和原始文件名\n",
        "folder_path = os.path.dirname(file_path)  # '/content/drive/My Drive/BAAI'\n",
        "file_name = os.path.basename(file_path)   # 'train-00000-of-00015.parquet'\n",
        "\n",
        "# 分割文件名和扩展名\n",
        "file_name_base, file_extension = os.path.splitext(file_name)  # 'train-00000-of-00015', '.parquet'\n",
        "\n",
        "# 构造新文件名\n",
        "new_file_name = f\"{file_name_base}_{current_date}{file_extension}\"  # 'train-00000-of-00015_2025-04-22.parquet'\n",
        "\n",
        "# 构造新文件的完整路径\n",
        "new_file_path = os.path.join(folder_path, new_file_name)  # '/content/drive/My Drive/BAAI/train-00000-of-00015_2025-04-22.parquet'\n",
        "\n",
        "# 步骤 3：保存 DataFrame 到新文件\n",
        "df.to_json(new_file_path, orient='records', lines=True, index=False, force_ascii=False)\n",
        "\n",
        "# 打印确认\n",
        "print(f\"文件已保存到: {new_file_path}\")"
      ],
      "metadata": {
        "id": "MPppuZWNYCV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceIdKzUwZccl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}